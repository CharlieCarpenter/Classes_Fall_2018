scale_x_discrete(labels = xaxis)
}
mGRP %>% NB_heatmap()
range(mGRP$Model_Coef$Estimate)
NB_heatmap <- function(modsum, low_grad, high_grad, mid_grad, midpoint = 0,
low_lim, high_lim, mute_cols = T,
main, xlab, ylab, subtitle, xaxis, top_taxa = 10){
if(missing(main)) main <- NULL ; if(missing(xlab)) xlab <- NULL
if(missing(subtitle)) subtitle <- NULL ; if(missing(ylab)) ylab <- NULL
if(missing(xaxis)) xaxis <- modsum$Model_Coef$Coef %>% unique %>% .[-1]
if(missing(low_grad)) low_grad <- "blue"; if(missing(high_grad)) high_grad <- "red"
if(missing(mid_grad)) mid_grad <- "beige"
## selecting the Taxa, model Coefs, and RR, and arranging them by RR within Taxa
CC <- modsum$Model_Coef %>%
dplyr::select(Taxa, Coef, Estimate) %>%
dplyr::filter(Coef != "(Intercept)")
if(missing(low_lim)) low_lim <- -max(abs(max(CC$Estimate)),
abs(min(CC$Estimate)))
if(missing(high_lim)) high_lim <- max(abs(max(CC$Estimate)),
abs(min(CC$Estimate)))
ar <- CC %>%
dplyr::group_by(Taxa) %>%
dplyr::summarise(max = max(Estimate), avg = mean(Estimate)) %>%
left_join(CC, by = "Taxa") %>%
unique %>%
dplyr::arrange(desc(max), desc(avg))
#  CC %>% filter(Taxa %in% unique(ar$Taxa)[1:top_taxa]) %>%
CC %>%
ggplot(aes(Coef, Taxa)) +
geom_tile(aes(fill = Estimate)) +
theme_bw() +
scale_fill_gradient2(limits = c(low_lim, high_lim),
low = low_grad,
high = high_grad,
mid = mid_grad,
midpoint = midpoint) +
labs(title = main, x = xlab, y = ylab, subtitle = subtitle) +
scale_x_discrete(labels = xaxis)
}
mGRP %>% NB_heatmap()
NB_heatmap <- function(modsum, low_grad, high_grad, mid_grad, midpoint = 0,
low_lim, high_lim, mute_cols = T,
main, xlab, ylab, subtitle, xaxis, top_taxa = 10){
if(missing(main)) main <- NULL ; if(missing(xlab)) xlab <- NULL
if(missing(subtitle)) subtitle <- NULL ; if(missing(ylab)) ylab <- NULL
if(missing(xaxis)) xaxis <- modsum$Model_Coef$Coef %>% unique %>% .[-1]
if(missing(low_grad)) low_grad <- "blue"; if(missing(high_grad)) high_grad <- "red"
if(missing(mid_grad)) mid_grad <- "beige"
## selecting the Taxa, model Coefs, and RR, and arranging them by RR within Taxa
CC <- modsum$Model_Coef %>%
dplyr::select(Taxa, Coef, Estimate) %>%
dplyr::filter(Coef != "(Intercept)")
if(missing(low_lim)) low_lim <- -max(abs(max(CC$Estimate)),
abs(min(CC$Estimate)))
if(missing(high_lim)) high_lim <- max(abs(max(CC$Estimate)),
abs(min(CC$Estimate)))
ar <- CC %>%
dplyr::group_by(Taxa) %>%
dplyr::summarise(max = max(Estimate), avg = mean(Estimate)) %>%
left_join(CC, by = "Taxa") %>%
unique %>%
dplyr::arrange(desc(max), desc(avg))
CC %>% filter(Taxa %in% unique(ar$Taxa)[1:top_taxa]) %>%
ggplot(aes(Coef, Taxa)) +
geom_tile(aes(fill = Estimate)) +
theme_bw() +
scale_fill_gradient2(limits = c(low_lim, high_lim),
low = low_grad,
high = high_grad,
mid = mid_grad,
midpoint = midpoint) +
labs(title = main, x = xlab, y = ylab, subtitle = subtitle) +
scale_x_discrete(labels = xaxis)
}
mGRP %>% NB_heatmap()
mGRP %>% NB_heatmap(top_taxa = 5)
library(pwr) ## For power.t.test
library(tidyselect) ## For tidyselect
## Fold change of 2 on log_2 scale is effect size of 1
## sd estimate = 0.25 (MA section 3.8)
## using pwr.t.test for many different power levels
pwr.lvls <- seq(0.8,0.95, by = 0.05)
## d = delta/sd
pwr.n <- sapply(pwr.lvls, function(x){
pwr.t.test(d = 4, sig.level = 0.0001, power = x, type = "two.sample", alternative =
"two.sided")$n
}
)
## sample size calculation using the estimates from MA equation 3.2
samp_size_fun <- function(pwr, sig, delta, se){
4*((qnorm(sig/2) + qnorm(1-pwr))/(delta/se))^2
}
MA.n <- sapply(pwr.lvls, samp_size_fun, sig = 0.0001, delta = 1, se = 0.25)
install.packages("ssiz")
install.packages("ssize")
install.packages(c("matrixStats", "GSA", "shiny", "openxlsx"))
source("http://bioconductor.org/biocLite.R")
biocLite("impute")
install.packages("~/Documents/Classes_Fall_2018/BIOS 7659/HW1/Codessamr_2.0.tar", repos = NULL, type="source")
biocLite("ssize")
install.packages("~/Documents/Classes_Fall_2018/BIOS 7659/HW1/Codes/samr_2.0.tar", repos = NULL, type="source")
## Reading in data sets
array_data <- read.table("~/Documents/Classes_Fall_2018/BIOS 7659/HW1/arraydata.txt", row.names = 1, header = TRUE)
## Reading in data sets
array_data <- read.table("~/Documents/Classes_Fall_2018/BIOS 7659/HW1/arraydata.txt", row.names = 1, header = TRUE)
sd_values <- read.table("~/Documents/Classes_Fall_2018/BIOS 7659/HW1/sdvalues.txt", row.names = 1, header = TRUE)
pvalues <- read.table("~/Documents/Classes_Fall_2018/BIOS 7659/HW1/pvalues.txt", row.names = 1, header = TRUE)
pvalues <- read.table("~/Documents/Classes_Fall_2018/BIOS 7659/HW1/pvalues.txt")
View(sd_values)
sd_values <- read.table("~/Documents/Classes_Fall_2018/BIOS 7659/HW1/sdvalues.txt")
sd_values
head(sd_values)
head(pvalue)
head(pvalues)
pwr.n <- sapply(c(0.8, 0.95), function(x){
pwr.t.test(d = 1/.5, sig.level = 0.0001, power = x, type = "two.sample", alternative =
"two.sided")$n
}
)
sapply(c(0.8, 0.95), function(x){
pwr.t.test(d = 1/.5, sig.level = 0.0001, power = x, type = "two.sample", alternative =
"two.sided")$n
}
)
sapply(c(0.8, 0.95), function(x){
pwr.t.test(d = 1/.5, sig.level = 0.001, power = x, type = "two.sample", alternative =
"two.sided")$n
}
)
ttt <- pwr.t.test(d = 1/.5, sig.level = 0.001, power = 0.8, type = "two.sample", alternative =
"two.sided")
ttt$note
?ssize::power.t.test.FDR()
ssize::power.t.test.FDR(sd = .5, delta = 1, FDR.level = 0.05, power = c(.8,.95),
type = "one.sample", alternative = "two.sided")
seq(0.8,0.95, by = 0.05)
pwr.lvls <- seq(0.8,0.95, by = 0.05)
## d = delta/sd
pwr.n <- sapply(pwr.lvls, function(x){
pwr.t.test(d = 4, sig.level = 0.0001, power = x, type = "two.sample", alternative =
"two.sided")$n
}
)
pwr.lvls
pwr.n
ssize::power.t.test.FDR(sd = .5, delta = 1, FDR.level = 0.05, pi0 = .999,
power = c(.8,.95), type = "one.sample",
alternative = "two.sided")
sapply(c(.8,.95), function(x){
ssize::power.t.test.FDR(sd = .5, delta = 1, FDR.level = 0.05, pi0 = .999,
power = x, type = "one.sample", alternative = "two.sided")
}
)
FDR.n <- sapply(c(.8,.95), function(x){
ssize::power.t.test.FDR(sd = .5, delta = 1, FDR.level = 0.05, pi0 = .999,
power = x, type = "one.sample",
alternative = "two.sided")$n
}
)
FDR.n
sapply(pwr.lvls, function(x){
pwr.t.test(d = 1/.5, sig.level = 0.001, power = x, type = "two.sample",
alternative= "two.sided")$n
}
)
head(sd_values)
ssize::ssize(sd = .5, delta = 1, sig.level = 0.001, power = 0.8)
sapply(c(0.8,0.95), function(x){
ssize::ssize(sd = .5, delta = 1, sig.level = 0.001, power = x)
}
)
sd_values$V2
```{r}
ssize.n <- sapply(sd_values$V2, function(x){
ssize::ssize(sd = .5, delta = 1, sig.level = 0.001, power = x)
}
)
ssize.n <- sapply(sd_values$V2, function(x){
ssize::ssize(sd = .5, delta = 1, sig.level = 0.001, power = x)
}
)
ssize::ssize.plot(ssize.n)
sapply(sd_values$V2, function(x){
ssize::ssize(sd = x, delta = 1, sig.level = 0.001, power = 0.8)
}
) %>%
ssize::ssize.plot()
library(pwr) ## For power.t.test
library(tidyselect) ## For tidyselect
## Fold change of 2 on log_2 scale is effect size of 1
## sd estimate = 0.25 (MA section 3.8)
## using pwr.t.test for many different power levels
pwr.lvls <- seq(0.8,0.95, by = 0.05)
## d = delta/sd
pwr.n <- sapply(pwr.lvls, function(x){
pwr.t.test(d = 4, sig.level = 0.0001, power = x, type = "two.sample", alternative =
"two.sided")$n
}
)
source("http://bioconductor.org/biocLite.R")
biocLite("ssize")
library(pwr) ## For power.t.test
library(tidyverse) ## For tidyverse
sapply(sd_values$V2, function(x){
ssize::ssize(sd = x, delta = 1, sig.level = 0.001, power = 0.8)
}
) %>%
ssize::ssize.plot()
sapply(sd_values$V2, function(x){
ssize::ssize(sd = x, delta = 1, sig.level = 0.001, power = 0.8)
}
) %>%
ssize::ssize.plot(xlim = c(0,50))
sapply(sd_values$V2, function(x){
ssize::ssize(sd = x, delta = 1, sig.level = 0.001, power = 0.8)
}
) %>%
ssize::ssize.plot(xlim = c(0,50))
sapply(sd_values$V2, function(x){
ssize::ssize(sd = x, delta = 1, sig.level = 0.001, power = 0.8)
}
) %>%
ssize::ssize.plot(xlim = c(0,30))
sapply(sd_values$V2, function(x){
ssize::ssize(sd = x, delta = 1, sig.level = 0.001, power = 0.8)
}
) %>%
ssize::ssize.plot(xlim = c(0,30))
plot.pwr.8 <- sapply(sd_values$V2, function(x){
ssize::ssize(sd = x, delta = 1, sig.level = 0.001, power = 0.8)
}
)
plot.pwr.8 <- sapply(sd_values$V2, function(x){
ssize::ssize(sd = x, delta = 1, sig.level = 0.001, power = 0.95)
}
)
set.seed(5)
ssize::ssize.plot(plot.pwr.8, xlim = c(0,50))
plot.pwr.8 <- sapply(sd_values$V2, function(x){
ssize::ssize(sd = x, delta = 1, sig.level = 0.001, power = 0.8)
}
)
plot.pwr.8 <- sapply(sd_values$V2, function(x){
ssize::ssize(sd = x, delta = 1, sig.level = 0.001, power = 0.8)
}
)
ssize::ssize.plot(plot.pwr.8, xlim = c(0,50))
set.seed(5)
ssize::ssize.plot(plot.pwr.8, xlim = c(0,50))
set.seed(5)
plot.pwr.8 <- sapply(sd_values$V2, function(x){
ssize::ssize(sd = x, delta = 1, sig.level = 0.001, power = 0.8)
}
)
ssize::ssize.plot(plot.pwr.8, xlim = c(0,50))
ssize::ssize.plot(plot.pwr.8, xlim = c(0,30))
set.seed(5)
plot.pwr.8 <- sapply(sd_values$V2, function(x){
ssize::ssize(sd = x, delta = 1, sig.level = 0.001, power = 0.8)
}
)
set.seed(5)
plot.pwr.95 <- sapply(sd_values$V2, function(x){
ssize::ssize(sd = x, delta = 1, sig.level = 0.001, power = 0.95)
}
)
ssize::ssize.plot(plot.pwr.8, xlim = c(0,30))
ssize::ssize.plot(plot.pwr.8)
ssize::ssize.plot(plot.pwr.8, xlim = c(0,30))
ssize::ssize.plot(plot.pwr.95, xlim = c(0,30))
ssize::ssize.plot(plot.pwr.8, xlim = c(0,30))
plot.pwr.8 <- ssize::ssize(sd = sd_values$V2, delta = 1,
sig.level = 0.001, power = 0.8)
ssize::ssize.plot(plot.pwr.8, xlim = c(0,30))
set.seed(5)
plot.pwr.8 <- ssize::ssize(sd = sd_values$V2, delta = 1,
sig.level = 0.001, power = 0.8)
set.seed(5)
plot.pwr.95 <- ssize::ssize(sd = sd_values$V2, delta = 1,
sig.level = 0.001, power = 0.95)
ssize::ssize.plot(plot.pwr.8, xlim = c(0,30))
ssize::ssize.plot(plot.pwr.95, xlim = c(0,30))
dim(sd_values)
ssize::ssize.plot(plot.pwr.8, xlim = c(0,30), main = "Power = 0.8")
source('~/Documents/Research/Current/Jed_Stuff/03_tidy_microbiome/Code/tidy_MIBI.R')
meta.dat <- read.table("~/Documents/Research/Current/Jed_Stuff/04_2wk_infant_analysis/RawData/Master_Sequence_Full_2018.txt")
gen <- read.table("~/Documents/Research/Current/Jed_Stuff/04_2wk_infant_analysis/RawData/Complete_Runs_all_taxa_cts.txt")
genus.set <- tidy_MIBI(genus = gen,
meta = meta.dat)
genus.set <- tidy_MIBI(genus = gen, meta = meta.dat)
source('~/Documents/Research/Current/Jed_Stuff/03_tidy_microbiome/Code/tidy_MIBI.R')
source('~/Documents/Research/Current/Jed_Stuff/03_tidy_microbiome/Code/tidy_MIBI.R')
source('~/Documents/Research/Current/Jed_Stuff/03_tidy_microbiome/Code/tidy_MIBI.R')
meta.dat <- read.table("~/Documents/Research/Current/Jed_Stuff/04_2wk_infant_analysis/RawData/Master_Sequence_Full_2018.txt")
gen <- read.table("~/Documents/Research/Current/Jed_Stuff/04_2wk_infant_analysis/RawData/Complete_Runs_all_taxa_cts.txt")
genus.set <- tidy_MIBI(genus = gen, meta = meta.dat)
mtoy <- NB_mods(genus.set, rank = "Genus", Group, EWG)
gen <- read.table("~/Documents/Research/Current/Jed_Stuff/04_2wk_infant_analysis/RawData/Complete_Runs_Class_cts.txt")
gen <- read.table("~/Documents/Research/Current/Jed_Stuff/04_2wk_infant_analysis/RawData/Complete_Runs_Class_cts.txt")
gen <- read.table("~/Documents/Research/Current/Jed_Stuff/01_datasets/Data/OTU_Tabs/Complete_Runs_Class_cts.txt")
genus.set <- tidy_MIBI(genus = gen, meta = meta.dat)
mtoy <- NB_mods(genus.set, rank = "Genus", Group, EWG)
rm(gen)
cla <- read.table("~/Documents/Research/Current/Jed_Stuff/01_datasets/Data/OTU_Tabs/Complete_Runs_Class_cts.txt")
class.set <- tidy_MIBI(class = cla, meta = meta.dat)
mtoy <- NB_mods(class.set, rank = "Genus", Group, EWG)
head(class.set)
mtoy <- NB_mods(class.set, rank = "Class", Group, EWG)
class.set <- tidy_MIBI(class = cla, meta = meta.dat)
View(class.set)
mtoy <- NB_mods(class.set, rank = "Class", Group, EWG)
mtoy <- NB_mods(class.set, rank = "Class", EWG)
mtoy <- NB_mods(class.set, rank = "Class", Group, EWG)
source('~/Documents/Research/Current/Jed_Stuff/03_tidy_microbiome/Code/tidy_MIBI.R')
meta.dat <- read.table("~/Documents/Research/Current/Jed_Stuff/04_2wk_infant_analysis/RawData/Master_Sequence_Full_2018.txt")
cla <- read.table("~/Documents/Research/Current/Jed_Stuff/01_datasets/Data/OTU_Tabs/Complete_Runs_Class_cts.txt")
class.set <- tidy_MIBI(class = cla, meta = meta.dat)
View(cla)
mtoy <- NB_mods(class.set, rank = "Class", Group, EWG)
mtoy <- NB_mods(class.set, rank = "Class", Group)
source('~/Documents/Research/Current/Jed_Stuff/03_tidy_microbiome/Code/tidy_MIBI.R')
meta.dat <- read.table("~/Documents/Research/Current/Jed_Stuff/04_2wk_infant_analysis/RawData/Master_Sequence_Full_2018.txt")
cla <- read.table("~/Documents/Research/Current/Jed_Stuff/01_datasets/Data/OTU_Tabs/Complete_Runs_Class_cts.txt")
class.set <- tidy_MIBI(class = cla, meta = meta.dat)
mtoy <- NB_mods(class.set, rank = "Class", Group)
#############################################################
## Program Name: DataClean.R							                 ##
## Purpose: To read in the dataset and label the variables ##
## 			   Create any new variables.					             ##
## Output: A Clean .csv file is exported for reading in to ##
##         all other analysis files.					             ##
## Created by: Nichole Carlson (R Code by: Kevin Josey)		 ##
#############################################################
# READ IN THE RAW DATA AND CREATE VARIABLE TRANSFORMS
# Note: This is the place where I would come back to
#       for any data cleaning, outlier removal more
#       transforms.  This keeps all data cleaning
#		    and variable decisions in one place.
# Dependencies
library(readr)
library(dplyr)
library(magrittr)
# psa <- read_csv("C:/Repositories/Bios6623ClassExamples/PSA-Project/G1Analysis/DataRaw/prostate.csv")
psa <- read_csv("~/Downloads/prostate.csv")
colnames(psa) <- tolower(colnames(psa))
psaclean <- psa %>%
mutate(lpsa = log(psa),
grade6 = ifelse(gleason == 6, 1, 0),
grade7 = ifelse(gleason == 7, 1, 0),
grade8 = ifelse(gleason == 8, 1, 0)) %>%
mutate(gd6ageint = age*grade6,
gd7ageint = age*grade7,
gd8ageint = age*grade8)
# export the clean dataset for use in other analysis programs
# write_csv(psaclean, "C:/Repositories/Bios6623ClassExamples/PSA-Project/G1Analysis/Data/psaclean.csv")
write_csv(psaclean, "~/Downloads/psaclean.csv")
# further data cleaning based on reviewing descriptive statistics
psaclean2 <- psaclean %>%
filter(wt <= 400) %>%
mutate(cavolsviint = cavol*svi,
wtsviint = wt*svi,
agesviint = age*svi,
bphsviint = bph*svi,
cappensviint = cappen*svi,
gd6sviint = grade6*svi,
gd7sviint = grade7*svi,
gd8sviint = grade8*svi)
# export the clean dataset for use in other analysis programs
# write_csv(psaclean2, "C:/Repositories/Bios6623ClassExamples/PSA-Project/G1Analysis/Data/psaclean2.csv")
write_csv(psaclean2, "~/Downloads/psaclean2.csv")
rm(list = ls())
# Dependencies
library(readr)
library(rjags)
library(mcmcse)
install.packages('rjags')
library(rjags)
install.packages('readr')
install.packages('rjags')
library(mcmcse)
setwd("~/Documents/Classes_Fall_2018/BIOS 6624/Code")
psaclean2 <- read_csv("DataProcessed/psaclean2.csv")
setwd("~/Documents/Classes_Fall_2018/BIOS 6624")
psaclean2 <- read_csv("Data/psaclean2.csv")
View(psaclean2)
library(rjags)
install.packages('rjags')
library(rjags)
.Platform$pkgType
library(rjags)
####Run a linear model just to orient us using standard methods
agemodel <-lm(lpsa ~ age, data=psaclean2)
sink("Output/AgeLinearModelOutput.txt")
sink("Data/AgeLinearModelOutput.txt")
print(agemodel)
summary.lm(agemodel)
confint(agemodel)
sink()
# y is the outcome in your linear regression model
y <- c(psaclean2$lpsa)
# Now we set up the design matrix in our linear regression
# For the first question in worksheet 3 we are looking at an intercept and age
X <- model.matrix(~ age, data = psaclean2)
X
#These are variables needed in Rjags
#N is the number of observations in your dataset and p is the number of columns in the design matrix
N <- nrow(X)
p <- ncol(X)
a <- 0.001 # gamma shape for a non-informative prior
a <- 0.001 # gamma shape for a non-informative prior
b <- 0.001 # gamma rate for a non-informative prior
m <- rep(0, p) # mvnorm mean  (mean in the prior on the regression coefficients)
R <- matrix(0, p, p) # mvnorm covariance (1/var-cov in the prior on the regression coefficients)
diag(R) <- 0.001 # note that JAGS uses dispersion matrix (scalars) rather
R
# create data list to pass to JAGS
jags_dat <- list(y = y, X = X, N = N, p = p,
a = a, b = b, m = m, R = R)
mod <- jags.model("Code/linMod.jags", data = jags_dat, n.adapt = 1000, n.chains = 2)
mod <- jags.model("Code/linMod.jags", data = jags_dat, n.adapt = 1000, n.chains = 2)
# Sample observations from the posterior distributions
iter <- 25000 # number of draws for the MCMC
samples <- coda.samples(mod, variable.names = c("beta", "sigma2"), n.iter = iter) # generates matrix of draws from posterior dist.
# determine if the support of the parameter space is explored well (more adaptations)
plot(samples)
samples
str(samples)
# determine if the support of the parameter space is explored well (more adaptations)
plot(samples)
# determine amount of autocorrelation between draws (thinning parameter)
par(mfrow = c(ceiling(ncol(as.matrix(samples))/2), 2), mar = rep(1, 4))
apply(as.matrix(samples), 2, acf) # We will learn later how to assess if this graph says our MCMC worked correctly.
hpd <- function(x, alpha = 0.05){
n = length(x)
m = round(n * alpha)
x = sort(x)
y = x[(n - m + 1):n] - x[1:m]
z = min(y)
k = which(y == z)[1]
c(x[k], x[n - m + k])
}
draws <- as.matrix(samples)
out_mat <- matrix("", nrow = ncol(draws), ncol = 5)
out_mat[,1] <- c(colnames(X), "sigma2") # names
out_mat[,2] <- apply(draws, 2, function(x) round(mcse(x)$est, 3)) # batch mean
out_mat[,3] <- apply(draws, 2, function(x) round(mcse(x)$se, 3)) # MCSE
out_mat[,4] <- round(apply(draws, 2, sd), 3) # Std. Dev.
out_mat[,5] <- apply(draws, 2, function(x)
paste("(", round(hpd(x)[1], 3), ", ", round(hpd(x)[2], 3), ")", sep = "")) # HPDI
colnames(out_mat) <- c("Parameter", "Estimate", "MCSE", "Std. Dev.", "95% HPDI")
write_csv(as.data.frame(out_mat), "Output/bayes-est-worksheet3-agemodel.csv")
write_csv(as.data.frame(out_mat), "Data/bayes-est-worksheet3-agemodel.csv")
sink("Data/GleasonLinearModelOutput.txt")
print(gleasonmodel)
summary.lm(gleasonmodel)
confint(gleasonmodel)
anova(gleasonmodel)
###########################################################################
#################LOG PSA AND GLEASON SCORE ANALYSIS########################
###########################################################################
####Run a linear model just to orient us using standard methods
psaclean2$gleason<-as.factor(psaclean2$gleason)
gleasonmodel <-lm(lpsa ~ gleason, data=psaclean2)
sink("Data/GleasonLinearModelOutput.txt")
print(gleasonmodel)
summary.lm(gleasonmodel)
confint(gleasonmodel)
anova(gleasonmodel)
sink()
# y is the outcome in your linear regression model
y <- c(psaclean2$lpsa)
# Now we set up the design matrix in our linear regression
# For the first question in worksheet 3 we are looking at an intercept and age
X <- model.matrix(~ grade7 + grade8, data = psaclean2)
#These are variables needed in Rjags
#N is the number of observations in your dataset and p is the number of columns in the design matrix
N <- nrow(X)
p <- ncol(X)
a <- 0.001 # gamma shape for a non-informative prior
b <- 0.001 # gamma rate for a non-informative prior
m <- rep(0, p) # mvnorm mean  (mean in the prior on the regression coefficients)
R <- matrix(0, p, p) # mvnorm covariance (1/var-cov in the prior on the regression coefficients)
diag(R) <- 0.001 # note that JAGS uses dispersion matrix (scalars) rather
# create data list to pass to JAGS
jags_dat <- list(y = y, X = X, N = N, p = p,
a = a, b = b, m = m, R = R)
mod <- jags.model("Code/jags/linMod.jags", data = jags_dat2, n.adapt = 1000, n.chains = 2)
# Sample observations from the posterior distributions
iter <- 25000 # number of draws for the MCMC
mod <- jags.model("Code/linMod.jags", data = jags_dat2, n.adapt = 1000, n.chains = 2)
# create data list to pass to JAGS
jags_dat2 <- list(y = y, X = X, N = N, p = p,
a = a, b = b, m = m, R = R)
mod <- jags.model("Code/linMod.jags", data = jags_dat2, n.adapt = 1000, n.chains = 2)
# Sample observations from the posterior distributions
iter <- 25000 # number of draws for the MCMC
samples <- coda.samples(mod, variable.names = c("beta", "sigma2"), n.iter = iter) # generates matrix of draws from posterior dist.
# determine if the support of the parameter space is explored well (more adaptations)
plot(samples)
# determine amount of autocorrelation between draws (thinning parameter)
par(mfrow = c(ceiling(ncol(as.matrix(samples))/2), 2), mar = rep(1, 4))
apply(as.matrix(samples), 2, acf) # We will learn later how to assess if this graph says our MCMC worked correctly.
draws <- as.matrix(samples)
out_mat <- matrix("", nrow = ncol(draws), ncol = 5)
out_mat[,1] <- c(colnames(X), "sigma2") # names
out_mat[,2] <- apply(draws, 2, function(x) round(mcse(x)$est, 3)) # batch mean
out_mat[,3] <- apply(draws, 2, function(x) round(mcse(x)$se, 3)) # MCSE
out_mat[,4] <- round(apply(draws, 2, sd), 3) # Std. Dev.
out_mat[,5] <- apply(draws, 2, function(x)
paste("(", round(hpd(x)[1], 3), ", ", round(hpd(x)[2], 3), ")", sep = "")) # HPDI
colnames(out_mat) <- c("Parameter", "Estimate", "MCSE", "Std. Dev.", "95% HPDI")
write_csv(as.data.frame(out_mat), "Data/bayes-est-worksheet3-gleasonmodel.csv")
